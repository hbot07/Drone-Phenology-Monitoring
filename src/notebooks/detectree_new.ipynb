{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d7aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18 (main, Jun  5 2025, 08:13:51) [Clang 14.0.6 ]\n",
      "Import error: No module named 'detectron2'\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics: show interpreter and key package versions\n",
    "import sys\n",
    "print('Python:', sys.version)\n",
    "try:\n",
    "    import rasterio, detectron2, detectree2\n",
    "    print('rasterio:', getattr(rasterio, '__version__', 'unknown'))\n",
    "    import importlib\n",
    "    print('detectron2:', importlib.metadata.version('detectron2'))\n",
    "    # print('detectree2:', getattr(detectree2, '__version__', 'unknown'))\n",
    "except Exception as e:\n",
    "    print('Import error:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5b458",
   "metadata": {},
   "source": [
    "# Detectree2 crown detection class\n",
    "\n",
    "This notebook provides a clean, class-based pipeline to run Detectree2 crown detection on orthomosaics found in `input/input_om`, and saves crowns as GeoPackages named like `OM1.gpkg` into `output/detected_polygons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3f6f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# PyTorch safe creators shim to handle numpy scalar/dtype inputs from downstream libs\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_map_numpy_dtype_to_torch\u001b[39m(dtype):\n\u001b[1;32m     23\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32: torch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m     25\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64: torch\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_: torch\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m     33\u001b[0m     }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# Pillow compatibility shim for detectron2 transforms\n",
    "if not hasattr(Image, 'LINEAR'):\n",
    "    Image.LINEAR = Image.BILINEAR\n",
    "if not hasattr(Image, 'CUBIC'):\n",
    "    Image.CUBIC = Image.BICUBIC\n",
    "if not hasattr(Image, 'LANCZOS'):\n",
    "    Image.LANCZOS = Image.LANCZOS if hasattr(Image, 'LANCZOS') else Image.BICUBIC\n",
    "\n",
    "# PyTorch safe creators shim to handle numpy scalar/dtype inputs from downstream libs\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def _map_numpy_dtype_to_torch(dtype):\n",
    "    mapping = {\n",
    "        np.float32: torch.float32,\n",
    "        np.float64: torch.float64,\n",
    "        np.float16: torch.float16,\n",
    "        np.int64: torch.int64,\n",
    "        np.int32: torch.int32,\n",
    "        np.int16: torch.int16,\n",
    "        np.int8: torch.int8,\n",
    "        np.uint8: torch.uint8,\n",
    "        np.bool_: torch.bool,\n",
    "    }\n",
    "    if isinstance(dtype, np.dtype):\n",
    "        dtype = dtype.type\n",
    "    return mapping.get(dtype, dtype)\n",
    "\n",
    "def _coerce_numpy_scalars(obj):\n",
    "    # Recursively convert numpy scalar types to native Python scalars within common containers\n",
    "    if isinstance(obj, np.generic):\n",
    "        return obj.item()\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        coerced = [_coerce_numpy_scalars(o) for o in obj]\n",
    "        return type(obj)(coerced) if not isinstance(obj, tuple) else tuple(coerced)\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _coerce_numpy_scalars(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "\n",
    "if not getattr(torch, \"_wrapped_torch_creators_numpy_dtype\", False):\n",
    "    def _wrap_creator(fn):\n",
    "        def _inner(*args, **kwargs):\n",
    "            if args:\n",
    "                args = ( _coerce_numpy_scalars(args[0]), ) + args[1:]\n",
    "            if \"dtype\" in kwargs:\n",
    "                kwargs[\"dtype\"] = _map_numpy_dtype_to_torch(kwargs[\"dtype\"])\n",
    "            return fn(*args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "    # Patch common creators used in preprocessing/prediction\n",
    "    for name in [\n",
    "        \"tensor\", \"as_tensor\", \"zeros\", \"zeros_like\", \"ones\", \"ones_like\",\n",
    "        \"empty\", \"empty_like\", \"full\", \"full_like\", \"arange\", \"linspace\",\n",
    "        \"logspace\", \"eye\", \"rand\", \"randn\",\n",
    "    ]:\n",
    "        if hasattr(torch, name):\n",
    "            setattr(torch, name, _wrap_creator(getattr(torch, name)))\n",
    "\n",
    "    torch._wrapped_torch_creators_numpy_dtype = True\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# detectree2 / detectron2\n",
    "from detectree2.preprocessing.tiling import tile_data\n",
    "from detectree2.models.train import setup_cfg\n",
    "from detectree2.models.predict import predict_on_data\n",
    "from detectree2.models.outputs import project_to_geojson, stitch_crowns, clean_crowns\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectreeConfig:\n",
    "    tiles_buffer: int = 20\n",
    "    tile_width: int = 45\n",
    "    tile_height: int = 45\n",
    "    dtype_bool: bool = True\n",
    "    iou_threshold: float = 0.7\n",
    "    confidence_threshold: float = 0.5\n",
    "    simplify_tolerance: float = 0.3\n",
    "    device: str = \"cpu\"  # set to 'cuda' if GPU available\n",
    "\n",
    "\n",
    "class DetectreeRunner:\n",
    "    \"\"\"\n",
    "    Clean, minimal class to tile, predict, stitch, clean and save crowns as GPKG.\n",
    "\n",
    "    Contract\n",
    "    - Input: path to orthomosaic (tif), path to trained .pth, optional output dir.\n",
    "    - Output: GeoDataFrame of crowns and a saved GPKG file.\n",
    "    - Errors: raises FileNotFoundError for missing inputs; RuntimeError for missing dependencies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Optional[DetectreeConfig] = None):\n",
    "        self.cfg = config or DetectreeConfig()\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_dir(path: str):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def install_detectree2():\n",
    "        subprocess.check_call([\"pip\", \"install\", \"git+https://github.com/PatBall1/detectree2.git\"])  # optional helper\n",
    "\n",
    "    def _setup_detection_cfg(self, trained_model_path: str):\n",
    "        if not os.path.exists(trained_model_path):\n",
    "            raise FileNotFoundError(f\"Model not found: {trained_model_path}\")\n",
    "        cfg = setup_cfg(update_model=trained_model_path)\n",
    "        # Force device if specified\n",
    "        try:\n",
    "            cfg.MODEL.DEVICE = self.cfg.device\n",
    "        except Exception:\n",
    "            pass\n",
    "        return cfg\n",
    "\n",
    "    def _tile(self, img_path: str, tiles_path: str):\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        self._ensure_dir(tiles_path)\n",
    "        tile_data(\n",
    "            img_path,\n",
    "            tiles_path,\n",
    "            self.cfg.tiles_buffer,\n",
    "            self.cfg.tile_width,\n",
    "            self.cfg.tile_height,\n",
    "            dtype_bool=self.cfg.dtype_bool,\n",
    "        )\n",
    "\n",
    "    def _predict(self, tiles_path: str, cfg):\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        predict_on_data(directory=tiles_path, predictor=predictor)\n",
    "\n",
    "    def _geo_project(self, tiles_path: str) -> str:\n",
    "        predictions_folder = os.path.join(tiles_path, \"predictions/\")\n",
    "        geo_predictions_folder = os.path.join(tiles_path, \"predictions_geo/\")\n",
    "        project_to_geojson(tiles_path, predictions_folder, geo_predictions_folder)\n",
    "        return geo_predictions_folder\n",
    "\n",
    "    def _stitch_and_clean(self, geo_predictions_folder: str) -> gpd.GeoDataFrame:\n",
    "        crowns = stitch_crowns(geo_predictions_folder, 1)\n",
    "        # CRS safety: ensure geodataframe has CRS by reading from a sample tile if missing\n",
    "        if crowns.crs is None:\n",
    "            # Try to infer CRS from a sidecar if present; otherwise leave None\n",
    "            pass\n",
    "        crowns = crowns[crowns.is_valid]\n",
    "        crowns = crowns.set_geometry(crowns.simplify(self.cfg.simplify_tolerance))\n",
    "        crowns = clean_crowns(crowns, self.cfg.iou_threshold, self.cfg.confidence_threshold)\n",
    "        return crowns\n",
    "\n",
    "    @staticmethod\n",
    "    def save_gpkg(crowns: gpd.GeoDataFrame, out_gpkg_path: str):\n",
    "        DetectreeRunner._ensure_dir(os.path.dirname(out_gpkg_path))\n",
    "        # If CRS is missing, try setting from EPSG:3857 as a fallback (most orthos are projected); better to inherit from source raster if available\n",
    "        if crowns.crs is None:\n",
    "            warnings.warn(\"Crowns GeoDataFrame has no CRS; saving without CRS. Consider setting CRS from source raster.\")\n",
    "        crowns.to_file(out_gpkg_path, driver=\"GPKG\")\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize(crowns: gpd.GeoDataFrame, img_path: Optional[str] = None, title: str = \"Predicted Crowns\"):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            with rasterio.open(img_path) as src:\n",
    "                show(src, ax=ax)\n",
    "            ax.set_title(\"Orthomosaic with Predicted Crowns\")\n",
    "        else:\n",
    "            ax.set_title(title)\n",
    "        crowns.plot(ax=ax, facecolor='none', edgecolor='red')\n",
    "        plt.show()\n",
    "\n",
    "    def run(self, img_path: str, trained_model_path: str, work_dir: str, out_gpkg_path: str, visualize: bool = False) -> gpd.GeoDataFrame:\n",
    "        # Validate model early to avoid costly tiling if missing\n",
    "        cfg = self._setup_detection_cfg(trained_model_path)\n",
    "        tiles_path = os.path.join(work_dir, \"tiles\")\n",
    "        self._tile(img_path, tiles_path)\n",
    "        self._predict(tiles_path, cfg)\n",
    "        geo_dir = self._geo_project(tiles_path)\n",
    "        crowns = self._stitch_and_clean(geo_dir)\n",
    "        self.save_gpkg(crowns, out_gpkg_path)\n",
    "        if visualize:\n",
    "            self.visualize(crowns, img_path)\n",
    "        return crowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137bd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path helpers and naming scheme\n",
    "from pathlib import Path\n",
    "\n",
    "def infer_output_name_from_orthomosaic(om_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Map sit_om1.tif -> OM1.gpkg, sit_om2.tif -> OM2.gpkg, etc.\n",
    "    Fallback: base name uppercased without extension + .gpkg\n",
    "    \"\"\"\n",
    "    stem = Path(om_filename).stem\n",
    "    # Try sit_om{n}\n",
    "    if stem.lower().startswith(\"sit_om\") and stem[6:].isdigit():\n",
    "        n = stem[6:]\n",
    "        return f\"OM{n}.gpkg\"\n",
    "    # Try lhc_om{n}\n",
    "    if stem.lower().startswith(\"lhc_om\") and stem[6:].isdigit():\n",
    "        n = stem[6:]\n",
    "        return f\"OM{n}.gpkg\"\n",
    "    # generic fallback\n",
    "    return f\"{stem.upper()}.gpkg\"\n",
    "\n",
    "INPUT_OM_DIR = \"/Users/hbot07/VS Code/Drone-Phenology-Monitoring/input/input_om\"\n",
    "OUTPUT_DIR = \"/Users/hbot07/VS Code/Drone-Phenology-Monitoring/output/detected_polygons\"\n",
    "WORK_DIR = \"/Users/hbot07/VS Code/Drone-Phenology-Monitoring/output/work\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# Model path set to provided model\n",
    "MODEL_PATH = \"/Users/hbot07/VS Code/Drone-Phenology-Monitoring/input/detectree_models/250312_flexi.pth\"\n",
    "\n",
    "# Pick one orthomosaic to test\n",
    "TEST_OM = \"sit_om1.tif\"\n",
    "IMG_PATH = os.path.join(INPUT_OM_DIR, TEST_OM)\n",
    "OUT_GPKG = os.path.join(OUTPUT_DIR, infer_output_name_from_orthomosaic(TEST_OM))\n",
    "TILES_WORK = os.path.join(WORK_DIR, Path(TEST_OM).stem)\n",
    "\n",
    "runner = DetectreeRunner()\n",
    "print(\"Image:\", IMG_PATH)\n",
    "print(\"Model:\", MODEL_PATH)\n",
    "print(\"Output GPKG:\", OUT_GPKG)\n",
    "print(\"Work dir:\", TILES_WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecef900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline on the selected orthomosaic and save GPKG with visualization\n",
    "import traceback\n",
    "try:\n",
    "    crowns = runner.run(\n",
    "        img_path=IMG_PATH,\n",
    "        trained_model_path=MODEL_PATH,\n",
    "        work_dir=TILES_WORK,\n",
    "        out_gpkg_path=OUT_GPKG,\n",
    "        visualize=True,\n",
    "    )\n",
    "    print(f\"Saved crowns: {OUT_GPKG}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Missing file:\", e)\n",
    "    print(\"Tip: ensure the model .pth exists at MODEL_PATH or set DETECTREE_MODEL env var.\")\n",
    "except Exception as e:\n",
    "    print(\"Error while running detection:\")\n",
    "    traceback.print_exc()\n",
    "    print(\"If detectron2/detectree2 are not installed for your Python kernel, install them and re-run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function to run by orthomosaic file name\n",
    "\n",
    "def run_and_save(om_filename: str, model_path: str = MODEL_PATH):\n",
    "    img_path = os.path.join(INPUT_OM_DIR, om_filename)\n",
    "    out_name = infer_output_name_from_orthomosaic(om_filename)\n",
    "    out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "    work = os.path.join(WORK_DIR, Path(om_filename).stem)\n",
    "    return runner.run(img_path, model_path, work, out_path, visualize=False)\n",
    "\n",
    "# Example:\n",
    "# run_and_save('sit_om2.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
